{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ae414f",
   "metadata": {},
   "source": [
    "# Using ML to predict the Sale Price of Bulldozers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801dcad-a398-4ff5-b3d3-7907d9d3c43f",
   "metadata": {},
   "source": [
    "<span style=\"color:violet\">Special thanks to Zero To Mastery Academy (https://academy.zerotomastery.io) and to its instructor Daniel Bourke.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02c62f",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">1. Problem Definition\n",
    "Prediction of future sale price of bulldozers, taking into account characteristics and examples of how much similar bulldozers have been sold for.\n",
    "## <span style=\"color:red\">2. Data\n",
    "##### Bluebook for Bulldozers\n",
    "Link to data & details: https://www.kaggle.com/c/bluebook-for-bulldozers/data\n",
    "<p></p>\n",
    "\n",
    "##### Background information on CSVs:\n",
    "* Train.csv is the training set, which contains data through the end of 2011.\n",
    "* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "* Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "## <span style=\"color:red\">3. Evaluation\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "For more see: www.kaggle.com/competitions/bluebook-for-bulldozers/overview/evaluation.\n",
    "<p></p>\n",
    "(The goal will be to minimize the RMSLE.)\n",
    "<p></p>\n",
    "\n",
    "## <span style=\"color:red\">4. Features\n",
    "A data dictionary is provided by Kaggle. See: https://www.kaggle.com/competitions/bluebook-for-bulldozers/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/TrainAndValid.csv\",low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2821426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "ax.scatter(df[\"saledate\"][:1000],df[\"SalePrice\"][:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72850938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SalePrice\"].plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df986997",
   "metadata": {},
   "source": [
    "### Parsing dates\n",
    "The original datatype of each value in the \"saledate\" column is of type \"object\" (= str) and needs to be converted into datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e7d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"saledate\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bee011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"saledate\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048144b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"saledate\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e49775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load of data set (TrainsAndValid.csv)\n",
    "df = pd.read_csv(\"data/TrainAndValid.csv\", low_memory=False, parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cf255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"saledate\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"saledate\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"saledate\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd1600",
   "metadata": {},
   "source": [
    "### Sorting DataFrame by \"saledate\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"saledate\",inplace=True,ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"saledate\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbf4d2",
   "metadata": {},
   "source": [
    "### Creating a backup of modified DataFrame (by copying df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd98f1a",
   "metadata": {},
   "source": [
    "### Adding datetime params for \"saledate\" column\n",
    "Each value in the \"saledate\" column will be extracted and saved in its own column. Afterwards the \"saledate\" column will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43da9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"saleYear\"] = df_tmp[\"saledate\"].dt.year\n",
    "df_tmp[\"saleMonth\"] = df_tmp[\"saledate\"].dt.month\n",
    "df_tmp[\"saleDay\"] = df_tmp[\"saledate\"].dt.day\n",
    "df_tmp[\"saleDayOfWeek\"] = df_tmp[\"saledate\"].dt.dayofweek\n",
    "df_tmp[\"saleDayOfYear\"] = df_tmp[\"saledate\"].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c819247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.drop(columns=[\"saledate\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbf5b9",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              random_state=42)\n",
    "\n",
    "# next step would be to fit the model:\n",
    "# model.fit(df_tmp.drop(\"SalePrice\",axis=1),df_tmp[\"SalePrice\"])\n",
    "\n",
    "# in the current state the fitting will provoke a ValueError,\n",
    "# since 44 columns in the data set are not of numeric data types,\n",
    "# hence, (the commented-out code will not be executed and)\n",
    "# the non-numeric data types have to be converted first into a processible, i.e. numeric data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_object_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc26cdd",
   "metadata": {},
   "source": [
    "### Converting Non-Numeric Objects (strings & NaN) to Categorical Data\n",
    "In order to use the data for ML model(s), it has to be converted from String- or NaN-objects to categorical data. Hence, the goal of the following modification is to change all non-numeric objects into numeric objects.\n",
    "<p></p>\n",
    "An overview of how to search for data types with pandas is to be found here: <a href=\"https://pandas.pydata.org/docs/reference/arrays.html\">pandas documentation</a> (see the subchapter \"Utilities\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_object_dtype(content):\n",
    "        df_tmp[label] = content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125388f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portays missing data per column in percent (%)\n",
    "df_tmp.isna().sum() / len(df_tmp) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad433d8b",
   "metadata": {},
   "source": [
    "### Saving processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.to_csv(\"data/train_tmp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9208b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tmp = pd.read_csv(\"data/train_tmp.csv\", low_memory=False)\n",
    "#df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b965e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the goal is to predict the sale price for bulldozers for the year 2012\n",
    "# based on data from 1989 to 2011, two DataFrames are created\n",
    "# (one only with the sale year 2012 and one excluding the sale year 2012)\n",
    "\n",
    "df_train = df_tmp[df_tmp[\"saleYear\"] != 2012]\n",
    "df_val = df_tmp[df_tmp[\"saleYear\"] == 2012]\n",
    "\n",
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e510a",
   "metadata": {},
   "source": [
    "### Filling missing numeric values with the median of the existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7156e",
   "metadata": {},
   "source": [
    "###### filling df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_train.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(f\"count: {count} (no NaN / null-values in the data set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e99970",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_train.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            #df_train[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            df_train[label] = content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_train.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(f\"count: {count} (no NaN / null-values in the data set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d58425",
   "metadata": {},
   "source": [
    "###### filling df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_val.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(f\"count: {count} (no NaN / null-values in the data set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaacd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_val.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            #df_val[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            df_val[label] = content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57917c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_val.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(f\"count: {count} (no NaN / null-values in the data set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce518b",
   "metadata": {},
   "source": [
    "### Filling and turning categorical values into numeric ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843efe2",
   "metadata": {},
   "source": [
    "###### fill df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_train.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(\"no NaN / null-values in the data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c69ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_train.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        #df_train[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        df_train[label] = pd.Categorical(content).codes+1 # the +1 is turning the default -1 (= NaN) to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_train.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(\"no NaN / null-values in the data set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34fa767",
   "metadata": {},
   "source": [
    "###### fill df_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_val.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(f\"count: {count}\")\n",
    "else:\n",
    "    print(\"no NaN / null-values in the data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4439cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_val.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        #df_val[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        df_val[label] = pd.Categorical(content).codes+1 # the +1 is turning the default -1 (= NaN) to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for label, content in df_val.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "            count+=pd.isnull(content).sum()\n",
    "if count > 0:\n",
    "    print(count)\n",
    "else:\n",
    "    print(f\"count: {count} (no NaN / null-values in the data set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25265f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(\"SalePrice\",axis=1), df_train[\"SalePrice\"]\n",
    "X_valid, y_valid = df_val.drop(\"SalePrice\",axis=1), df_val[\"SalePrice\"]\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eceb4d",
   "metadata": {},
   "source": [
    "### Model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2b3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# instantiate model\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              random_state=42)\n",
    "# fit model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3da82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested data is based on the same training data, which results in high score\n",
    "# (nearly 99%), but that means that no generalization can be drawn out of this\n",
    "\n",
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14279bfe",
   "metadata": {},
   "source": [
    "### Build an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd21ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def show_scores(model):\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(X_valid)\n",
    "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_pred),\n",
    "              \"Valid MAE\": mean_absolute_error(y_valid, val_pred),\n",
    "              \"Training RMSLE\": rmsle(y_train, train_pred),\n",
    "              \"Valid RMSLE\": rmsle(y_valid, val_pred),\n",
    "              \"Training R^2\": model.score(X_train, y_train),\n",
    "              \"Valid R^2\": model.score(X_valid, y_valid)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c13c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8bb13d",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5efd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_grid = {\"n_estimators\":np.arange(10,100,10),\n",
    "           \"max_depth\":[None,3,5.10],\n",
    "           \"min_samples_split\":np.arange(2,20,2),\n",
    "           \"min_samples_leaf\":np.arange(1,20,2),\n",
    "           \"max_features\":[0.5,1,\"sqrt\",\"auto\"],\n",
    "           \"max_samples\":[200000]}\n",
    "\n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n",
    "                                                    random_state=42),\n",
    "                              param_distributions=rf_grid,\n",
    "                              n_iter=100,\n",
    "                              cv=5,\n",
    "                              verbose=True)\n",
    "rs_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57340a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model hyperparams\n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b642f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_hyperparams_model = RandomForestRegressor(n_estimators=50,\n",
    "                                               min_samples_split=2,\n",
    "                                               min_samples_leaf=3,\n",
    "                                               max_features=0.5,\n",
    "                                               max_samples=None,\n",
    "                                               max_depth=None,\n",
    "                                               random_state=42)\n",
    "best_hyperparams_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(best_hyperparams_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041de35d",
   "metadata": {},
   "source": [
    "### Make predictions on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e84ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of test data set\n",
    "df_test = pd.read_csv(\"data/Test.csv\",low_memory=False,parse_dates=[\"saledate\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data set is given as argument to best hyperparam model\n",
    "test_pred = best_hyperparams_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc3719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df[\"saleYear\"] = df[\"saledate\"].dt.year\n",
    "    df[\"saleMonth\"] = df[\"saledate\"].dt.month\n",
    "    df[\"saleDay\"] = df[\"saledate\"].dt.day\n",
    "    df[\"saleDayOfWeek\"] = df[\"saledate\"].dt.dayofweek\n",
    "    df[\"saleDayOfYear\"] = df[\"saledate\"].dt.dayofyear\n",
    "    \n",
    "    df.drop(\"saledate\",\n",
    "            axis=1,\n",
    "            inplace=True)\n",
    "    \n",
    "    for label, content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "                #df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "                df[label] = content.fillna(content.median())\n",
    "    \n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            #df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            df[label] = pd.Categorical(content).codes+1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocess_data(df_test)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e57d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_hyperparams_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame()\n",
    "df_pred[\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_pred[\"SalesPrice\"] = test_pred\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(\"data/test_pred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(columns,importances,n=20):\n",
    "    df = (pd.DataFrame({\"features\":columns,\n",
    "                        \"feature_importances\":importances})\n",
    "          .sort_values(\"feature_importances\",\n",
    "                       ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(df[\"features\"][:n],\n",
    "            df[\"feature_importances\"][:20])\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns,best_hyperparams_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa79826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
